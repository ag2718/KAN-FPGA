{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aarushg/KAN-FPGA/KAN_Impl')\n",
    "from KANLinear import KAN, Quantizer\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 4\n"
     ]
    }
   ],
   "source": [
    "TP = 7\n",
    "FP = 3\n",
    "\n",
    "\n",
    "grid_range=[-2**(TP - FP - 1), 2**(TP - FP - 1)]\n",
    "resolution = int(2 ** TP)\n",
    "\n",
    "REGULARIZE_ACTIVATION = 0.001\n",
    "\n",
    "print(TP, FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/X_train_val.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_train\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/y_train_val.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m X_test\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/X_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train=torch.from_numpy(np.load('data/X_train_val.npy')).float().to(device)\n",
    "y_train=torch.from_numpy(np.load('data/y_train_val.npy')).float().to(device).argmax(dim=1)\n",
    "X_test=torch.from_numpy(np.load('data/X_test.npy')).float().to(device)\n",
    "y_test=torch.from_numpy(np.load('data/y_test.npy')).float().to(device).argmax(dim=1)\n",
    "\n",
    "# Create TensorDataset objects\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 64  # Adjust this based on your available memory\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = KAN([16,5,5], grid_size=30, spline_order=10, grid_eps=0.05, base_activation=nn.GELU, grid_range=grid_range, quantize=True, tp=TP, fp=FP, lut_res=resolution, quantize_clip=True).to(device)\n",
    "# model = KAN([16,4,5], grid_size=30, spline_order=3, grid_eps=0.05, base_activation=nn.GELU, grid_range=grid_range).to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "model.to(device)\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# Define learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(30):\n",
    "    # Train\n",
    "    model.train()\n",
    "    epoch_train_loss = 0  # Initialize loss for the epoch\n",
    "    total_batches = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for i, (inputs, labels) in enumerate(pbar):\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels.to(device)) + model.regularization_loss(regularize_activation=REGULARIZE_ACTIVATION, regularize_entropy=min(0.005 * epoch, 0.05), regularize_clipping=min(0.05 * epoch, 0.2))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "            accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
    "\n",
    "            fracs_clipped = []\n",
    "            for layer in model.layers:\n",
    "                fracs_clipped.extend(round(x.item(), 4) for x in layer.get_frac_clipped())\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'], frac_clipped=fracs_clipped)\n",
    "    \n",
    "    average_train_loss = epoch_train_loss / total_batches\n",
    "    training_loss.append(average_train_loss)  # Record the average training loss\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            val_loss += criterion(output, labels.to(device)).item() + model.regularization_loss(regularize_activation=0, regularize_entropy=0, regularize_clipping=0.2)\n",
    "            val_accuracy += (\n",
    "                (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
    "            )\n",
    "    val_loss /= len(testloader)\n",
    "    val_accuracy /= len(testloader)\n",
    "    testing_loss.append(val_loss)\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    REMAINING_FRACTION = model.prune_below_threshold(threshold=0.1)\n",
    "    print(f\"Overall remaining fraction (Epoch {epoch + 1}): \", REMAINING_FRACTION)\n",
    "\n",
    "    fracs_clipped = []\n",
    "    for layer in model.layers:\n",
    "        fracs_clipped.extend(x.item() for x in layer.get_frac_clipped())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}, Val Frac Clipped: {fracs_clipped}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily store quantizers\n",
    "stored_quantizers = []\n",
    "for layer in model.layers:\n",
    "    layer_quantizers = {}\n",
    "    if hasattr(layer, 'lut_inp_quantizer'):\n",
    "        layer_quantizers['inp'] = layer.lut_inp_quantizer\n",
    "        delattr(layer, 'lut_inp_quantizer')\n",
    "    if hasattr(layer, 'lut_out_quantizer'):\n",
    "        layer_quantizers['out'] = layer.lut_out_quantizer\n",
    "        delattr(layer, 'lut_out_quantizer')\n",
    "    stored_quantizers.append(layer_quantizers)\n",
    "\n",
    "# Save model without quantizers\n",
    "torch.save(model, f'models/model_{TP}t{FP}f_pr{1 - REMAINING_FRACTION}.pth')\n",
    "\n",
    "# Restore quantizers\n",
    "for layer, quantizers in zip(model.layers, stored_quantizers):\n",
    "    if 'inp' in quantizers:\n",
    "        layer.lut_inp_quantizer = quantizers['inp']\n",
    "    if 'out' in quantizers:\n",
    "        layer.lut_out_quantizer = quantizers['out']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
